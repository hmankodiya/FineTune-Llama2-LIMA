# FineTune-Llama2-LIMA

# QLoRA-Tuned Llama2 on the LIMA Dataset  

This repository contains the fine-tuning process of **Llama 2** using **QLoRA** on the **LIMA dataset**. The goal is to efficiently adapt Llama 2 to a high-quality instruction-following task using parameter-efficient tuning.

## 🚀 Overview  
- **Base Model**: Llama 2 (7B/13B/Other)  
- **Fine-Tuning Method**: QLoRA (Quantized LoRA)  
- **Dataset**: LIMA - A high-quality instruction dataset  
- **Objective**: Enhance Llama 2’s instruction-following capability while keeping computational requirements minimal  

## 📂 Results  
- Comming soon 

## ⚙️ Installation  
### **Dependencies**  
Ensure you have the following installed:  
```bash
pip install torch transformers peft accelerate bitsandbytes datasets 
