# FineTune-Llama2-LIMA

# QLoRA-Tuned Llama2 on the LIMA Dataset  

This repository contains the fine-tuning process of **Llama 2** using **QLoRA** on the **LIMA dataset**. The goal is to efficiently adapt Llama 2 to a high-quality instruction-following task using parameter-efficient tuning.

## ğŸš€ Overview  
- **Base Model**: Llama 2 (7B/13B/Other)  
- **Fine-Tuning Method**: QLoRA (Quantized LoRA)  
- **Dataset**: LIMA - A high-quality instruction dataset  
- **Objective**: Enhance Llama 2â€™s instruction-following capability while keeping computational requirements minimal  

## ğŸ“‚ Results  
- Comming soon 

## âš™ï¸ Installation  
### **Dependencies**  
Ensure you have the following installed:  
```bash
pip install torch transformers peft accelerate bitsandbytes datasets 
