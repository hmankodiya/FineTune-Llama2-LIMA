{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Get the absolute path of the project directory\n",
    "project_root = os.path.abspath(os.path.join(os.path.join(os.getcwd()), \"..\"))\n",
    "# Add the project root to sys.path\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "from argparse import ArgumentParser\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "from lima_dataset import load_lima_dataset, tokenize_text, format_prompt_func, EOT_TOKEN\n",
    "from utils import (\n",
    "    read_yaml,\n",
    "    get_model_config,\n",
    "    get_tokenizer_config,\n",
    "    get_generation_config,\n",
    "    get_generation_samples,\n",
    ")\n",
    "from model import (\n",
    "    load_model,\n",
    "    load_tokenizer,\n",
    "    generate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = read_yaml(\"./configs/generate_config_llama.yaml\")\n",
    "config = read_yaml(\"../configs/generate_config_llama_qlora.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('llama2',\n",
       " 'meta-llama/Llama-2-7b-hf',\n",
       " {'add_bos_token': True, 'add_eos_token': False})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_name, tokenizer_path, tokenizer_config = get_tokenizer_config(config)\n",
    "tokenizer = load_tokenizer(\n",
    "    tokenizer_name=tokenizer_name,\n",
    "    tokenizer_path=tokenizer_path,\n",
    "    tokenizer_config=tokenizer_config,\n",
    ")\n",
    "tokenizer_name, tokenizer_path, tokenizer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'force_download': False,\n",
       " 'device_map': 'cuda:0',\n",
       " 'use_cache': False,\n",
       " 'pad_token_id': 32000,\n",
       " 'tokenizer_length': 32002}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name, model_path, base_model_path, model_config = get_model_config(\n",
    "    config,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    tokenizer_length=len(tokenizer),\n",
    ")\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab234b2b9af54a15aa9b3d9b5505fb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model(\n",
    "    model_string=model_name,\n",
    "    model_path=model_path,\n",
    "    base_model_path=base_model_path,\n",
    "    model_config=model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_yaml('../configs/generate_config_llama_qlora.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = get_generation_config(config)\n",
    "generation_config[\"pad_token_id\"] = tokenizer.pad_token_id\n",
    "generation_config[\"eos_token_id\"] = tokenizer.eos_token_id\n",
    "# generation_config['max_new_tokens'] = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is reinforcement learning?',\n",
       " 'Explain black hole singularity.',\n",
       " 'Describe the role of mitochondria.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = get_generation_samples(config)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"I'm writing a NeurIPS paper about a new model architecture for processing and generating long texts. Here are some facts about the paper:\\n* The main trick is to replace some of the attention heads with an exponential moving average, where the decay rate is learned for each head. We call this architecture ExeMA.\\n* On language modeling, the perplexity difference between our model and a vanilla transformer is negligible, but that's because next-token prediction is almost always a local task, so perplexity won't be sensitive enough to detect any improvements in long-range understanding.\\n* However, on the SCROLLS benchmark, our model improves by 10% over the baseline.\\n* We also have a new metric for measuring coherence in generated text (CoGnaTe), where our model generates text that is 43% more coherent than the baseline.\\nHelp me write the paper's introduction.\"\n",
    "# # prompt = \"Plan a day trip in Tokyo. The spots need to be within walking distance to each other.\"\n",
    "# prompt = \"What medicine should I take when I get a cold?\"\n",
    "# # prompt = f\"{prompt}{EOT_TOKEN}\"\n",
    "\n",
    "outs = generate(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    # prompt_samples=prompt,\n",
    "    prompt_samples=samples,\n",
    "    generation_config=generation_config,\n",
    "    use_encode=False,\n",
    "    use_eot_token=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is reinforcement learning?\n",
      "Reinforcement learning is the branch of machine learning that helps machines learn from experiences.\n",
      "Reinforcement learning is the branch of machine learning that helps machines learn from experiences. It is used to teach machines to make decisions by providing feedback about whether or not those decisions are good.\n",
      "In reinforcement learning, the algorithm receives input from the environment, such as the position of a player in a video game or the temperature of a room. The algorithm then decides what action to take next based on that information and the goal of the game.\n",
      "There are two types of reinforcement learning: supervised and unsupervised. Supervised learning is when the algorithm receives input from an expert or a teacher who provides feedback about whether or not its decisions are good. Unsupervised learning is when there is no expert or teacher, so the algorithm must figure out what is good and bad on its own.\n",
      "Reinforcement learning has many applications in AI, including:\n",
      "-Self-driving cars\n",
      "-Robots that can navigate unfamiliar environments\n",
      "-Virtual assistants that can understand and respond to user queries\n",
      "-Applications that help people with disabilities\n",
      "-Social media platforms that can recommend content based on user preferences\n",
      "Reinforcement learning is a subset of machine learning that is used to teach machines to make decisions by providing feedback about whether or not those decisions are good.\n",
      "There are two types of reinforcement learning: supervised and unsupervised. Supervised learning is when the algorithm receives input from an expert or a teacher who provides feedback about whether or not its decisions are good. Unsupervised learning is when there is no expert or teacher, so the algorithm must figure out what is good and bad on its own.\n",
      "There are many applications for reinforcement learning, including self-driving cars, robots that can navigate unfamiliar environments, virtual assistants that can understand and respond to user queries, and social media platforms that can recommend content based on user preferences.\n",
      "Reinforcement learning is a subset of machine learning that helps machines learn from experiences. It is used to teach machines to make decisions by providing feedback about whether or not those decisions are good.\n",
      "There are two types of reinforcement learning: supervised and unsupervised. Supervised learning is when the algorithm receives input from an expert or a teacher\n"
     ]
    }
   ],
   "source": [
    "print(outs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain black hole singularity.\n",
      "I want to know about singularity and why we have to accept it?\n",
      "Asked by Rishabh Kumar | 13th Mar, 2015, 04:06: PM\n",
      "Singularities are points in space and time where physical quantities such as density or temperature diverge. This happens because of the extreme nature of the spacetime curvature at these points.\n",
      "We cannot understand the behavior of matter at singularities because at this point the laws of physics breaks down. So we have to accept it.\n"
     ]
    }
   ],
   "source": [
    "print(outs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
