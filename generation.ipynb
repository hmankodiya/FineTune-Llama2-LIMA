{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from argparse import ArgumentParser\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "from lima_dataset import load_lima_dataset, tokenize_text, format_prompt_func, EOT_TOKEN\n",
    "from utils import (\n",
    "    read_yaml,\n",
    "    get_model_config,\n",
    "    get_tokenizer_config,\n",
    "    get_split_config,\n",
    "    get_dataset_config,\n",
    "    get_trainer_config,\n",
    "    get_generation_config,\n",
    "    get_generation_samples,\n",
    "    get_lora_config,\n",
    "    _handle_seed,\n",
    "    DEVICE,\n",
    ")\n",
    "from model import (\n",
    "    tokenize_text,\n",
    "    load_model,\n",
    "    load_tokenizer,\n",
    "    load_pretrained_base_llama2_model,\n",
    "    load_lora_model,\n",
    "    generate,\n",
    "    compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = read_yaml(\"./configs/generate_config_llama.yaml\")\n",
    "config = read_yaml(\"./configs/generate_config_llama_qlora.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('llama2',\n",
       " 'meta-llama/Llama-2-7b-hf',\n",
       " {'add_bos_token': True, 'add_eos_token': False})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_name, tokenizer_path, tokenizer_config = get_tokenizer_config(config)\n",
    "tokenizer = load_tokenizer(\n",
    "    tokenizer_name=tokenizer_name,\n",
    "    tokenizer_path=tokenizer_path,\n",
    "    tokenizer_config=tokenizer_config,\n",
    ")\n",
    "tokenizer_name, tokenizer_path, tokenizer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'force_download': False,\n",
       " 'device_map': 'cuda:0',\n",
       " 'bnb_config': {'load_in_4bit': True,\n",
       "  'bnb_4bit_quant_type': 'nf4',\n",
       "  'bnb_4bit_compute_dtype': 'float16',\n",
       "  'bnb_4bit_use_double_quant': False},\n",
       " 'pad_token_id': 32000,\n",
       " 'tokenizer_length': 32002}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name, model_path, base_model_path, model_config = get_model_config(\n",
    "    config,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    tokenizer_length=len(tokenizer),\n",
    ")\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083c4132d6ca41f09b3b6602c7d8de5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\n",
    "    model_string=model_name,\n",
    "    model_path=model_path,\n",
    "    base_model_path=base_model_path,\n",
    "    model_config=model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_yaml(\"./configs/generate_config_llama_qlora.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = get_generation_config(config)\n",
    "generation_config[\"pad_token_id\"] = tokenizer.pad_token_id\n",
    "# generation_config['max_new_tokens'] = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"I'm writing a NeurIPS paper about a new model architecture for processing and generating long texts. Here are some facts about the paper:\\n* The main trick is to replace some of the attention heads with an exponential moving average, where the decay rate is learned for each head. We call this architecture ExeMA.\\n* On language modeling, the perplexity difference between our model and a vanilla transformer is negligible, but that's because next-token prediction is almost always a local task, so perplexity won't be sensitive enough to detect any improvements in long-range understanding.\\n* However, on the SCROLLS benchmark, our model improves by 10% over the baseline.\\n* We also have a new metric for measuring coherence in generated text (CoGnaTe), where our model generates text that is 43% more coherent than the baseline.\\nHelp me write the paper's introduction.\"\n",
    "# prompt = \"Plan a day trip in Tokyo. The spots need to be within walking distance to each other.\"\n",
    "prompt = \"What medicine should I take when I get a cold?\"\n",
    "# prompt = f\"{prompt}{EOT_TOKEN}\"\n",
    "outs = generate(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompt_samples=prompt,\n",
    "    generation_config=generation_config,\n",
    "    use_encode=False,\n",
    "    eot_token=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What medicine should I take when I get a cold? Keep it shortTrue! Colds are usually over within 7-10 days.\n",
      "What is the best way to treat colds and flu at home? Drink plenty of water, rest up, use paracetamol or ibuprofen if you have a fever (over 38°C), put on some layers of clothing so that your body can stay warm in case you start shivering. \u0006 \n",
      "Is there any medicine for cold sore treatment? There's no specific medication available but there are many things which may help relieve symptoms: - Apply an ice pack to reduce swelling around the mouth area; this will also numb pain temporarily by reducing blood flow into affected tissue areas such as lips/cheeks etc., allowing them time enough before they become too tender from rubbing against each other while sleeping during nighttime hours when we don't realize how much discomfort has been caused until morning comes along with its bright sunshine rays warming our faces again after having slept all through darkness without feeling anything unusual happening inside ourselves except maybe occasional twitches here &amp; there due mostly because muscles relax under stressful conditions like insomnia leading us towards daydreaming mode where everything seems perfect until reality hits hard once more come morning time rolls around...\n",
      "How do you cure yourself of being sick quickly? \u0006 * Get lots of rest. Avoid strenuous activities, especially those involving physical exertion. If possible, try not to move about too much throughout the day. Sleep whenever possible. Try taking naps instead of going out for walks or doing chores around the house. This helps give your immune system strength to fight off illnesses faster than usual.* Eat healthy foods. Make sure you eat something every few hours even though most people feel queasy when they first wake up from their nap. It’s important that nutrients reach your cells so they can repair themselves quicker than normal times would allow.* Take vitamin supplements. Vitamins play key roles in keeping your energy levels high enough so that your body doesn’t weaken easily under pressure situations (like fighting off viruses). These include B complexes which contain riboflavin, thiamin mononitrate\n"
     ]
    }
   ],
   "source": [
    "print(outs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
