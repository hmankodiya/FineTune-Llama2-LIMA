{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from argparse import ArgumentParser\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "from lima_dataset import load_lima_dataset, tokenize_text, format_prompt_func, EOT_TOKEN\n",
    "from utils import (\n",
    "    read_yaml,\n",
    "    get_model_config,\n",
    "    get_tokenizer_config,\n",
    "    get_split_config,\n",
    "    get_dataset_config,\n",
    "    get_trainer_config,\n",
    "    get_generation_config,\n",
    "    get_generation_samples,\n",
    "    get_lora_config,\n",
    "    _handle_seed,\n",
    "    DEVICE,\n",
    ")\n",
    "from model import (\n",
    "    tokenize_text,\n",
    "    load_model,\n",
    "    load_tokenizer,\n",
    "    load_pretrained_base_llama2_model,\n",
    "    load_lora_model,\n",
    "    generate,\n",
    "    compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_yaml(\"./configs/generate_config_llama.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('llama2',\n",
       " 'meta-llama/Llama-2-7b-hf',\n",
       " {'special_token_kwargs': {'pad_token': 'eos_token',\n",
       "   'additional_tokens': ['EOT_TOKEN']}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_name, tokenizer_path, tokenizer_config = get_tokenizer_config(config)\n",
    "tokenizer = load_tokenizer(\n",
    "    tokenizer_name=tokenizer_name,\n",
    "    tokenizer_path=tokenizer_path,\n",
    "    tokenizer_config=tokenizer_config,\n",
    ")\n",
    "tokenizer_name, tokenizer_path, tokenizer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'force_download': False,\n",
       " 'device_map': 'cuda:0',\n",
       " 'bnb_config': {'load_in_4bit': True,\n",
       "  'bnb_4bit_quant_type': 'nf4',\n",
       "  'bnb_4bit_compute_dtype': 'float16',\n",
       "  'bnb_4bit_use_double_quant': False}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name, model_path, base_model_path, model_config = get_model_config(config)\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config['pad_token_id'] = tokenizer.pad_token_id\n",
    "model_config['tokenizer_length'] = len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = load_pretrained_base_llama2_model(\n",
    "#     base_model_path, **model_config\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366ede5b6df64f86b9665002938df2e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\n",
    "    model_string=model_name,\n",
    "    model_path=model_path,\n",
    "    base_model_path=base_model_path,\n",
    "    model_config=model_config,\n",
    ")\n",
    "# base_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "# base_model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from peft import PeftModel\n",
    "# model = PeftModel.from_pretrained(\n",
    "#     base_model, \"/home/hmankodi/instruct_tuning/TrainingLogs/checkpoint-468\"\n",
    "# )\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_length': 2048,\n",
       " 'top_p': 0.9,\n",
       " 'temperature': 0.7,\n",
       " 'num_beams': 1,\n",
       " 'top_k': None,\n",
       " 'do_sample': True,\n",
       " 'repetition_penalty': 1.2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_config = get_generation_config(config)\n",
    "generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt = \"I'm writing a NeurIPS paper about a new model architecture for processing and generating long texts. Here are some facts about the paper:\\n* The main trick is to replace some of the attention heads with an exponential moving average, where the decay rate is learned for each head. We call this architecture ExeMA.\\n* On language modeling, the perplexity difference between our model and a vanilla transformer is negligible, but that's because next-token prediction is almost always a local task, so perplexity won't be sensitive enough to detect any improvements in long-range understanding.\\n* However, on the SCROLLS benchmark, our model improves by 10% over the baseline.\\n* We also have a new metric for measuring coherence in generated text (CoGnaTe), where our model generates text that is 43% more coherent than the baseline.\\nHelp me write the paper's introduction.\"\n",
    "prompt = \"Plan a day trip in Tokyo. The spots need to be within walking distance to each other.\"\n",
    "# prompt = \"What medicine should I take when I get a cold?\"\n",
    "# prompt = f\"{prompt}{EOT_TOKEN}\"\n",
    "outs = generate(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompt_samples=prompt,\n",
    "    generation_config=generation_config,\n",
    "    use_encode=True,\n",
    ")\n",
    "model.config.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plan a day trip in Tokyo. The spots need to be within walking distance to each other. [EOT] Here's an itinerary:\n",
      "\n",
      "* Start your morning by visiting the Meiji Shrine, which is located at 1-chomei, Minato City and surrounded by trees of the Imperial Palace Garden. Then walk around the shrines and learn about Japanese history and culture from the signboards on display.\n",
      "* From there you can take a bus or train to reach Asakusa district where you will find one of Japan’s most famous temples – Sensoji Temple. This temple has been standing for more than 200 years and features a large red gate that was built as part of its restoration work after World War II. If you are lucky enough to come here during cherry blossom season then make sure not miss out viewing some beautiful sakura flowers! There are also many stalls offering traditional food like okonomiyaki (a savory pancake) so don’t forget try them before leaving this place;\n",
      "* After exploring all these attractions head over towards Akihabara District which is known for being home to electronic shops, manga stores & maid cafes etc.. Here people go crazy shopping while others enjoy playing video games with their friends at arcades nearby area called UDX Arcade Complex or watching live performances inside Animate Store Theater. You may even get lucky enough finding rare items if check carefully through countless boxes displayed everywhere across streets outside buildings owned companies such as Yodobashi Camera Shop/Yahoo! Bookstore Co., Ltd., BicCamera Inc./Nihon Keizai Shimbun Inc.;\n",
      "* Last but not least head over towards Harajuku Area where youngsters gather every weekend wearing colorful costumes inspired by different pop cultures including JPop idols (singers), vampire series characters etcetera according to current trends among teenagers today worldwide due mainly influence coming from Korean drama shows broadcasted widely throughout Asia region since last decade especially South Korea itself becoming biggest source inspiration what makes dress code look similar between both countries nowadays despite geographical distance separating them two continents apart!.  Since they often wear weird clothes therefore making tourist easy identify who resides local neighborhood since foreigners usually stick out compared everyone else surrounding scene however no worries because majority locals wouldn’t mind seeing new faces wandering around looking lost without guide leading way unlike certain areas across globe where hostility shown towards strangers arriving unannounced into community especially ones carrying camera equipment along with selfie stick gear set up ready snap pictures whenever possible opportunity presents itself!! Now that should give you good idea how spend entire day sightseeing major metropolis capital city Tokyo Japan enjoying fun filled experience without breaking bank balance budget limit too much!!! Enjoy :)  Reference - VisitTokyo  www.visittokyo.jp   harajuku-guidebook  https://www.harajukuguidebook.com/en    asknippon  http://asknippon.coocanjs.jp/#!what_to_do&category=653&page=1&from=&to=     japantravel  en.japantravel.com                             obscuretraveller  http://theobscurestraveller.blogspot.sg/2014/08/meetup-with-bizarre-people-of-harajuku.html  travelfish  travelfish.org         wikipedia  en.wikipedia.org         \n",
      "\n",
      "Sources : [Plan a Day Trip in Tokyo](https://www.tripadvisor.in/Attractions-g197727-Activities-c56-Tokyo_Japan.html) , [Visiting Tokyo For First Timers](http://www.tripoto.com/~visiting-tokyo-for-first-timers-2dccbf6fbaeac#toplist), [What To Do In Tokyo?](https://www.google.co.in/?gws_rd=ssl#q=%22what+to+do%22++tokyo&start=10).\n"
     ]
    }
   ],
   "source": [
    "print(outs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
