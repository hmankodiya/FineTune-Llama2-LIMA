dataset_config:
  desc: LIMA Instruct Finetunning Dataset
  train:
    dataset_path: GAIR/lima
    sub_split_size: null

tokenizer_config:
  tokenizer_name: llama2
  tokenizer_path: "meta-llama/Llama-2-7b-hf"
  add_bos_token: true
  add_eos_token: false
  special_token_kwargs:
    pad_token: "[pad]"
    additional_tokens:
      - EOT_TOKEN

model_config:
  model_name: llama2-base
  model_path: /home/hmankodi/instruct_tuning/FineTune-Llama2-LIMA/TrainingLogs/runs/llama2_instruct_fulltrain_lora/model
  base_model_path: meta-llama/Llama-2-7b-hf
  force_download: false
  device_map: cuda:0

generation_config:
  max_new_tokens: 500
  top_p: 0.9
  temperature: 0.8
  num_beams: 1
  top_k: null
  do_sample: True
  repetition_penalty: 1

generation_samples:
  - What is reinforcement learning?
  - Explain black hole singularity.
