dataset_config:
  desc: LIMA Instruct Finetunning Test Dataset
  test:
    dataset_path: GAIR/lima
    sub_split_size: null

tokenizer_config:
  tokenizer_name: llama2
  tokenizer_path: "meta-llama/Llama-2-7b-hf"
  add_bos_token: true
  add_eos_token: false
  special_token_kwargs:
    pad_token: "[pad]"
    additional_tokens:
      - EOT_TOKEN

# QLORA LLama finetuned
# model_config:
#   model_name: llama2-finetuned
#   base_model_path: meta-llama/Llama-2-7b-hf
#   # model_path: /home/hmankodi/instruct_tuning/FineTune-Llama2-LIMA/TrainingLogs/checkpoint-728
#   model_path: /home/hmankodi/instruct_tuning/FineTune-Llama2-LIMA/TrainingLogs/runs/qlora_llama2_instruct_fulltrain_1/model
#   force_download: false
#   device_map: cuda:0
#   bnb_config:
#     load_in_4bit: true
#     bnb_4bit_quant_type: nf4
#     bnb_4bit_compute_dtype: "float16"
#     bnb_4bit_use_double_quant: false
#   use_cache: False

# LLama base
model_config:
  model_name: llama2-base
  base_model_path: meta-llama/Llama-2-7b-hf
  force_download: false
  device_map: cuda:0
  # bnb_config:
  #   load_in_4bit: true
  #   bnb_4bit_quant_type: nf4
  #   bnb_4bit_compute_dtype: "float16"
  #   bnb_4bit_use_double_quant: false
  use_cache: False

generation_config:
  max_new_tokens: 500
  top_p: 0.9
  temperature: 0.8
  num_beams: 1
  top_k: null
  do_sample: True
  repetition_penalty: 1

generation_samples:
  - What is reinforcement learning?
  - Explain black hole singularity.
  - Describe the role of mitochondria.
