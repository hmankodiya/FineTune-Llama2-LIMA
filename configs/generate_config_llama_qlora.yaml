dataset_config:
  desc: LIMA Instruct Finetunning Test Dataset
  test:
    dataset_path: GAIR/lima
    sub_split_size: null


tokenizer_config:
  tokenizer_name: llama2
  tokenizer_path: "meta-llama/Llama-2-7b-hf"
  special_token_kwargs:
    pad_token: eos_token
    # additional_tokens: 
    #   - EOT_TOKEN

# QLORA LLama finetuned
# model_config:
#   model_name: llama2-finetuned
#   model_path: /home/hmankodi/instruct_tuning/FineTune-Llama2-LIMA/TrainingLogs/checkpoint-468
#   base_model_path: meta-llama/Llama-2-7b-hf
#   force_download: false
#   device_map: cuda:0
#   bnb_config:
#     load_in_4bit: true
#     bnb_4bit_quant_type: nf4
#     bnb_4bit_compute_dtype: "float16"
#     bnb_4bit_use_double_quant: false

model_config:
  model_name: llama2-base
  # model_path: /home/hmankodi/instruct_tuning/FineTune-Llama2-LIMA/TrainingLogs/checkpoint-468
  base_model_path: meta-llama/Llama-2-7b-hf
  force_download: false
  device_map: cuda:0
  # bnb_config:
  #   load_in_4bit: true
  #   bnb_4bit_quant_type: nf4
  #   bnb_4bit_compute_dtype: "float16"
  #   bnb_4bit_use_double_quant: false

# generation_config:
#   max_length: 2048
#   top_p: 0.9
#   temperature: 0.7
#   num_beams: 1
#   top_k: null
#   do_sample: True
#   repetition_penalty: 1.2

generation_config:
  max_length: 2048
  top_p: 0.9
  temperature: 0.7
  num_beams: 1
  top_k: null
  do_sample: True
  repetition_penalty: 1.2

generation_samples:
  - this is a good product
  - this is a bad product
  - this is a very stupid product
