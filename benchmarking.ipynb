{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm  # Import tqdm for progress tracking\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    LlamaForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    LlamaTokenizer,\n",
    "    GenerationConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'meta-llama/Llama-2-7b-hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346ec6fbceac48c48fc0099d7653a0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_dict = {\n",
    "    \"load_in_4bit\": True,\n",
    "    \"bnb_4bit_quant_type\": \"nf4\",\n",
    "    \"bnb_4bit_compute_dtype\": 'float16',\n",
    "    \"bnb_4bit_use_double_quant\": False,\n",
    "}\n",
    "bnb_config = BitsAndBytesConfig(**bnb_dict)\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    # device_map='cpu'\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='cuda:0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizer(name_or_path='meta-llama/Llama-2-7b-hf', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversations': ['Can brain cells move? By movement I mean long distance migration (preferably within the brain only).',\n",
       "  'The question is relatively broad and one should take into account that the brain not only consists of neurons, but also glial cells (supportive cells) and pre-mitotic neuronal stem cells. Furthermore, as critical fellow-scientists have indicated, developmental stage is very important, as the developing embryonic brain is very different from the adult brain.\\nHowever, after sifting through various publications, the answer to the question is actually remarkably simple: Yes, brain cells migrate.\\nIn  the adult brain glial cells migrate in the brain (Klämbt, 2009). Glial cells are involved in a myriad of functions, but a notable example of migrating glial cells are the oligodendrocytes that migrate relative long distances to find their target axons onto which they wrap themselves to form the insulating myelin sheath (Tsai and Miller, 2002).\\nNeuronal stem cells migrate over long distances in response to injury (Imitola et al., 2004) and they migrate from specific stem-cell locations (e.g., hippocampus and subventricular zone) to other regions (Clarke, 2003).\\nPost-mitotic, but non-differentiated neurons have been shown to migrate in the adult brain in fish (Scott et al., 2012), and in mammals and non-human primates as well (Sawada et al., 2011).\\nNot surprisingly, glial cells, stem cells and neurons also migrate during embryonic development. Most notably, post-mitotic neurons destined to fulfill peripheral functions have to migrate over relatively long distances from the neural crest to their target locations (Neuroscience, 2nd ed, Neuronal Migration).'],\n",
       " 'source': 'stackexchange'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'GAIR/lima'\n",
    "split = 'train'\n",
    "dataset = load_dataset(dataset_name, split=split)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = dataset.train_test_split(test_size=0.2)\n",
    "split_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"do_sample\": true,\n",
       "  \"max_length\": 2048,\n",
       "  \"repetition_penalty\": 1.2,\n",
       "  \"temperature\": 0.7,\n",
       "  \"top_k\": null,\n",
       "  \"top_p\": 0.9\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    # max_new_tokens=10,\n",
    "    max_length=2048,\n",
    "    top_p=0.9,\n",
    "    temperature=0.7,\n",
    "    num_beams=1,\n",
    "    top_k=None,\n",
    "    do_sample=True,\n",
    "    repetition_penalty=1.2,\n",
    ")\n",
    "generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Outputs:   0%|          | 0/300 [00:00<?, ?sample/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Outputs: 100%|██████████| 300/300 [1:13:13<00:00, 14.65s/sample]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generated outputs dynamically to ./generated_outputs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_file = \"./generated_outputs.json\"\n",
    "\n",
    "try:\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"[\\n\")  # Start of JSON array\n",
    "        success = False  # Flag to track successful writes\n",
    "\n",
    "        with tqdm(total=len(dataset), desc=\"Generating Outputs\", unit=\"sample\") as pbar:\n",
    "            for idx, prompt in enumerate(dataset):\n",
    "                try:\n",
    "                    tokenized_prompt = tokenizer.encode(\n",
    "                        prompt[\"conversations\"][0], return_tensors=\"pt\"\n",
    "                    ).to(device=\"cuda:0\")\n",
    "\n",
    "                    logits = model.generate(\n",
    "                        tokenized_prompt, generation_config=generation_config\n",
    "                    )\n",
    "                    decoded_text = tokenizer.batch_decode(\n",
    "                        logits, skip_special_tokens=True\n",
    "                    )[0]\n",
    "\n",
    "                    # Create a JSON entry\n",
    "                    output_entry = {\n",
    "                        \"index\": idx,\n",
    "                        \"original_prompt\": prompt[\"conversations\"][0],\n",
    "                        \"generated_output\": decoded_text,\n",
    "                    }\n",
    "\n",
    "                    # Write to file immediately (JSON streaming)\n",
    "                    json.dump(output_entry, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "                    # Add a comma for the next entry, except for the last one\n",
    "                    if idx < len(dataset) - 1:\n",
    "                        f.write(\",\\n\")\n",
    "\n",
    "                    success = (\n",
    "                        True  # Mark that at least one entry was successfully written\n",
    "                    )\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating output for index {idx}: {e}\")\n",
    "\n",
    "                pbar.update(1)  # Update the progress bar after each sample\n",
    "\n",
    "        f.write(\"\\n]\")  # End of JSON array\n",
    "\n",
    "    if not success:\n",
    "        print(\n",
    "            \"No outputs were successfully generated. Please check your model and dataset.\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Saved generated outputs dynamically to {output_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Fatal error: Unable to write to file {output_file}. Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
